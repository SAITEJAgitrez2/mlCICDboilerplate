{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change pwd to c:\\\\Users\\\\SaiTeja\\\\PROJECTS\\\\MLCICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\SaiTeja\\\\PROJECTS\\\\MLCICD'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True) \n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textSummarizer.constants import *\n",
    "from textSummarizer.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        # ðŸ”¹ Debug: Print loaded YAML\n",
    "        print(\"DEBUG: Loaded Config =\", self.config)\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        # ðŸ”¹ Debug: Print values retrieved from YAML\n",
    "        print(f\"DEBUG: source_URL = {config.get('source_URL')}\")\n",
    "        print(f\"DEBUG: local_data_file = {config.get('local_data_file')}\")\n",
    "        print(f\"DEBUG: unzip_dir = {config.get('unzip_dir')}\")\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-02 20:41:39,520: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-02 20:41:39,526: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-02 20:41:39,528: INFO: common: created directory at: artifacts]\n",
      "DEBUG: Loaded Config = {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/SAITEJAgitrez2/datasets/raw/refs/heads/main/samsumdata.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_validation': {'root_dir': 'artifacts/data_validation', 'STATUS_FILE': 'artifacts/data_validation/status.txt', 'ALL_REQUIRED_FILES': ['train', 'test', 'validation']}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'data_path': 'artifacts/data_ingestion/samsum_dataset', 'tokenizer_name': 'google/pegasus-cnn_dailymail'}, 'model_trainer': {'root_dir': 'artifacts/model_trainer', 'data_path': 'artifacts/data_transformation/samsum_dataset', 'model_ckpt': 'google/pegasus-cnn_dailymail'}, 'model_evaluation': {'root_dir': 'artifacts/model_evaluation', 'data_path': 'artifacts/data_transformation/samsum_dataset', 'model_path': 'artifacts/model_trainer/pegasus-samsum-model', 'tokenizer_path': 'artifacts/model_trainer/tokenizer', 'metric_file_name': 'artifacts/model_evaluation/metrics.csv'}}\n",
      "DEBUG: source_URL = https://github.com/SAITEJAgitrez2/datasets/raw/refs/heads/main/samsumdata.zip\n",
      "DEBUG: local_data_file = artifacts/data_ingestion/data.zip\n",
      "DEBUG: unzip_dir = artifacts/data_ingestion\n",
      "[2025-03-02 20:41:39,529: INFO: common: created directory at: artifacts/data_ingestion]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "data_ingestion_config = config.get_data_ingestion_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from textSummarizer.logging import logger\n",
    "from textSummarizer.utils.common import get_size\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        \"\"\"Downloads a file from the given URL if it does not already exist.\"\"\"\n",
    "        local_file = Path(self.config.local_data_file)\n",
    "\n",
    "        if local_file.exists() and local_file.stat().st_size > 0:\n",
    "            logger.info(f\"File already exists: {local_file} ({get_size(local_file)})\")\n",
    "            return\n",
    "\n",
    "        # ðŸ”¹ Check if `source_URL` is empty\n",
    "        if not self.config.source_URL or self.config.source_URL.strip() == \"\":\n",
    "            raise ValueError(\"source_URL is missing or empty in config.yaml\")\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Downloading file from {self.config.source_URL} ...\")\n",
    "\n",
    "            # ðŸ”¹ Debug print before download\n",
    "            print(f\"DEBUG: Attempting to download from {self.config.source_URL}\")\n",
    "            print(f\"DEBUG: Saving to {local_file}\")\n",
    "\n",
    "            # ðŸ”¹ Open a request to the URL\n",
    "            with request.urlopen(self.config.source_URL) as response:\n",
    "                print(f\"DEBUG: HTTP Response Code = {response.status}\")\n",
    "                if response.status != 200:\n",
    "                    raise Exception(f\"HTTP Error: {response.status} while downloading {self.config.source_URL}\")\n",
    "\n",
    "                # ðŸ”¹ Save the file\n",
    "                with open(local_file, \"wb\") as out_file:\n",
    "                    shutil.copyfileobj(response, out_file)\n",
    "\n",
    "            # ðŸ”¹ Verify file size after download\n",
    "            print(f\"DEBUG: Downloaded file size = {local_file.stat().st_size} bytes\")\n",
    "            if local_file.stat().st_size == 0:\n",
    "                raise Exception(f\"Download failed: File is empty after downloading {self.config.source_URL}\")\n",
    "\n",
    "            logger.info(f\"Download complete: {local_file} ({get_size(local_file)})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Download failed: {e}\")\n",
    "            raise Exception(f\"Failed to download {self.config.source_URL}: {e}\")\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"Extract ZIP file using system tar command, with better error handling.\"\"\"\n",
    "        unzip_path = Path(self.config.unzip_dir)\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        local_zip = Path(self.config.local_data_file)\n",
    "\n",
    "        if not local_zip.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {local_zip}\")\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Extracting ZIP file using system `tar` command to {unzip_path} ...\")\n",
    "\n",
    "            # Run tar, but capture errors without stopping execution\n",
    "            result = subprocess.run(\n",
    "                [\"tar\", \"-xf\", str(local_zip), \"-C\", str(unzip_path)],\n",
    "                capture_output=True,\n",
    "                text=True\n",
    "            )\n",
    "\n",
    "            # ðŸ”¹ If tar returned an error but extracted files, ignore the error\n",
    "            if result.returncode != 0:\n",
    "                if any(Path(unzip_path).iterdir()):  # Check if files were extracted\n",
    "                    logger.warning(f\"Extraction completed with warnings: {result.stderr}\")\n",
    "                else:\n",
    "                    raise ValueError(f\"Extraction failed: {result.stderr}\")\n",
    "\n",
    "            logger.info(f\"Extraction complete using system tar command.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Extraction failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-02 20:41:49,692: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-02 20:41:49,696: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-03-02 20:41:49,698: INFO: common: created directory at: artifacts]\n",
      "DEBUG: Loaded Config = {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/SAITEJAgitrez2/datasets/raw/refs/heads/main/samsumdata.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'data_validation': {'root_dir': 'artifacts/data_validation', 'STATUS_FILE': 'artifacts/data_validation/status.txt', 'ALL_REQUIRED_FILES': ['train', 'test', 'validation']}, 'data_transformation': {'root_dir': 'artifacts/data_transformation', 'data_path': 'artifacts/data_ingestion/samsum_dataset', 'tokenizer_name': 'google/pegasus-cnn_dailymail'}, 'model_trainer': {'root_dir': 'artifacts/model_trainer', 'data_path': 'artifacts/data_transformation/samsum_dataset', 'model_ckpt': 'google/pegasus-cnn_dailymail'}, 'model_evaluation': {'root_dir': 'artifacts/model_evaluation', 'data_path': 'artifacts/data_transformation/samsum_dataset', 'model_path': 'artifacts/model_trainer/pegasus-samsum-model', 'tokenizer_path': 'artifacts/model_trainer/tokenizer', 'metric_file_name': 'artifacts/model_evaluation/metrics.csv'}}\n",
      "DEBUG: source_URL = https://github.com/SAITEJAgitrez2/datasets/raw/refs/heads/main/samsumdata.zip\n",
      "DEBUG: local_data_file = artifacts/data_ingestion/data.zip\n",
      "DEBUG: unzip_dir = artifacts/data_ingestion\n",
      "[2025-03-02 20:41:49,700: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-03-02 20:41:49,702: INFO: 2476352350: Downloading file from https://github.com/SAITEJAgitrez2/datasets/raw/refs/heads/main/samsumdata.zip ...]\n",
      "DEBUG: Attempting to download from https://github.com/SAITEJAgitrez2/datasets/raw/refs/heads/main/samsumdata.zip\n",
      "DEBUG: Saving to artifacts\\data_ingestion\\data.zip\n",
      "DEBUG: HTTP Response Code = 200\n",
      "DEBUG: Downloaded file size = 23627009 bytes\n",
      "[2025-03-02 20:41:52,492: INFO: 2476352350: Download complete: artifacts\\data_ingestion\\data.zip (~ 23073 KB)]\n",
      "[2025-03-02 20:41:52,493: INFO: 2476352350: Extracting ZIP file using system `tar` command to artifacts\\data_ingestion ...]\n",
      "[2025-03-02 20:41:52,734: WARNING: 2476352350: Extraction completed with warnings: data.zip: Refusing to overwrite archive: No error\n",
      "tar: Error exit delayed from previous errors.\n",
      "]\n",
      "[2025-03-02 20:41:52,734: INFO: 2476352350: Extraction complete using system tar command.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
